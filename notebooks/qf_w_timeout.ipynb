{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varun\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\sqlcopilot-cwclWRYE-py3.10\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "from concurrent.futures import ThreadPoolExecutor, TimeoutError\n",
    "from collections import defaultdict\n",
    "import os\n",
    "from src.query_fix.utils import *\n",
    "from openai import OpenAI\n",
    "from transformers import AutoProcessor, MarkupLMModel\n",
    "import time\n",
    "\n",
    "def fetch_results_with_timeout(database_path, query):\n",
    "    \"\"\"Function to fetch results with a timeout.\"\"\"\n",
    "    # Create a new connection and cursor in each thread\n",
    "    conn = sqlite3.connect(database_path)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(query)\n",
    "    \n",
    "    # Extract column names only if it's a SELECT query\n",
    "    if cursor.description is not None:\n",
    "        columns = [description[0] for description in cursor.description]\n",
    "    else:\n",
    "        columns = []  # No columns for non-SELECT queries\n",
    "    \n",
    "    result = cursor.fetchall()\n",
    "    conn.close()  # Close the connection after fetching results\n",
    "    return columns, result\n",
    "\n",
    "def query_fix(\n",
    "    database_name: str,\n",
    "    database_root_path: str,\n",
    "    database_path: str,\n",
    "    candidates: dict[str, str],\n",
    "    model: str,\n",
    "    ir: list[str],\n",
    "    question: str,\n",
    "    hint: str,\n",
    "    ground_truth: str,\n",
    "    markup_processor: AutoProcessor,\n",
    "    markup_model: MarkupLMModel,\n",
    "    n_retries: int=10,\n",
    "):\n",
    "    client = OpenAI(\n",
    "        base_url=os.environ['BASE_URL_DEEPSEEK'],\n",
    "        api_key=os.environ['API_KEY_DEEPSEEK']\n",
    "    )\n",
    "\n",
    "    llm = LLM(\n",
    "        client = client,\n",
    "        model = model, \n",
    "        gen_params = {\n",
    "            'STREAM': False,\n",
    "            'TEMPERATURE': 0,\n",
    "            'MAX_NEW_TOKENS': 2048 \n",
    "        }\n",
    "    )\n",
    "\n",
    "    methods = []\n",
    "    candidates_tmp = []\n",
    "    for k, v in candidates.items():\n",
    "        methods.append(v)\n",
    "        candidates_tmp.append(k)\n",
    "    \n",
    "    candidates = candidates_tmp\n",
    "\n",
    "    fixed_flags = defaultdict(bool)\n",
    "    fixed_queries = []\n",
    "    qents = []\n",
    "    method_percents = []\n",
    "    all_qr = {}\n",
    "    attempts = 0\n",
    "\n",
    "    while attempts < n_retries:\n",
    "        correct_index = False\n",
    "        new_candidates = []\n",
    "        intermediate_qr = []\n",
    "\n",
    "        for i, query in enumerate(candidates):\n",
    "            try:\n",
    "                if fixed_flags[i] == 1:\n",
    "                    new_candidates.append(query)\n",
    "\n",
    "                    # Use ThreadPoolExecutor to apply timeout for fetchall\n",
    "                    with ThreadPoolExecutor() as executor:\n",
    "                        future = executor.submit(fetch_results_with_timeout, database_path, query)\n",
    "                        try:\n",
    "                            result, columns = future.result(timeout=5)  # Timeout in seconds\n",
    "                        except TimeoutError:\n",
    "                            print(f\"Query {i} timed out.\")\n",
    "                            result = []  \n",
    "                            columns = []\n",
    "\n",
    "                    intermediate_qr.append((query, result))\n",
    "                    continue\n",
    "                else:\n",
    "                    conn = sqlite3.connect(database_path)\n",
    "                    cursor = conn.cursor()\n",
    "\n",
    "                    # Use ThreadPoolExecutor to apply timeout for fetchall\n",
    "                    with ThreadPoolExecutor() as executor:\n",
    "                        future = executor.submit(fetch_results_with_timeout, database_path, query)\n",
    "                        try:\n",
    "                            result, columns = future.result(timeout=5)  # Timeout in seconds\n",
    "                        except TimeoutError:\n",
    "                            print(f\"Query {i} timed out.\")\n",
    "                            result = []\n",
    "                            columns = []\n",
    "                    \n",
    "                    print(f\"query {i}, result {result}\")\n",
    "                    correct_flag = check_exec_accuracy(database_path=database_path, query=query, ground_truth_query=ground_truth)\n",
    "                    if correct_flag:\n",
    "                        correct_index = i\n",
    "                    conn.close()\n",
    "                    fixed_queries.append((query, result))\n",
    "                    intermediate_qr.append((query, result))\n",
    "                    new_candidates.append(query)\n",
    "                    fixed_flags[i] = 1\n",
    "            \n",
    "            except Exception as e:\n",
    "                fixed_flags[i] = 0\n",
    "                query = query_fixer(\n",
    "                    database_name=database_name,\n",
    "                    database_root_path=database_root_path,\n",
    "                    ir=ir,\n",
    "                    query_to_correct=query,\n",
    "                    question=question,\n",
    "                    hint=hint,\n",
    "                    result=e,\n",
    "                    model=llm\n",
    "                )\n",
    "                query = parse_query_fix_output(query)\n",
    "                new_candidates.append(query)\n",
    "                intermediate_qr.append((query, e))\n",
    "\n",
    "        all_qr[attempts] = intermediate_qr\n",
    "        all_features = []\n",
    "        \n",
    "        for cand in new_candidates:\n",
    "            try:\n",
    "                # Use ThreadPoolExecutor to apply timeout for fetchall\n",
    "                with ThreadPoolExecutor() as executor:\n",
    "                    future = executor.submit(fetch_results_with_timeout, database_path, cand)\n",
    "                    try:\n",
    "                        results, columns = future.result(timeout=10)  # Timeout in seconds\n",
    "                    except TimeoutError:\n",
    "                        print(f\"Query for candidate {cand} timed out.\")\n",
    "                        results = [] \n",
    "                        columns = []\n",
    "\n",
    "                html_result = sql_result_to_html(column_names=columns, result=results)\n",
    "                features = html_to_features(\n",
    "                    html_string=html_result, \n",
    "                    markup_lm_processor=markup_processor, \n",
    "                    markup_lm_model=markup_model,\n",
    "                )\n",
    "                all_features.append(features.detach().squeeze(dim=0))\n",
    "            \n",
    "            except sqlite3.Error as e:\n",
    "                print(f\"An error occurred: {e}\")\n",
    "                html_result = sql_result_to_html(error=e)\n",
    "                features = html_to_features(\n",
    "                    html_string=html_result, \n",
    "                    markup_lm_processor=markup_processor, \n",
    "                    markup_lm_model=markup_model,\n",
    "                )\n",
    "                all_features.append(features.detach().squeeze(dim=0))\n",
    "        \n",
    "        pi_correct = False\n",
    "        if correct_index:\n",
    "            clusters_DB, pi_correct = cluster_sql_queries(embeddings=np.array(all_features), correct_ind=correct_index)\n",
    "        else:\n",
    "            clusters_DB = cluster_sql_queries(embeddings=np.array(all_features))\n",
    "        \n",
    "        entropy, cluster_percentages = calculate_semantic_entropy(clusters=clusters_DB, methods=methods)\n",
    "        qents.append(entropy)\n",
    "        method_percents.append(cluster_percentages)\n",
    "        attempts += 1\n",
    "\n",
    "    log_values = {\"INTERMEDIATE_QR\": all_qr} \n",
    "    if pi_correct:\n",
    "        return fixed_queries, qents, log_values, pi_correct, method_percents\n",
    "    else:\n",
    "        return fixed_queries, qents, log_values, None, method_percents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varun\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\sqlcopilot-cwclWRYE-py3.10\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: no such column: T1.City\n",
      "An error occurred: no such column: S1.school_name\n",
      "An error occurred: no such column: f.School\n",
      "An error occurred: no such column: T1.City\n",
      "An error occurred: no such column: S1.school_name\n",
      "An error occurred: no such column: f.School_Name\n"
     ]
    }
   ],
   "source": [
    "database_name = \"california_schools\"\n",
    "database_path = f\"{os.environ['DATABASE_ROOT_PATH']}/{database_name}/{database_name}.sqlite\"\n",
    "database_root_path = f\"{os.environ['DATABASE_ROOT_PATH']}/{database_name}\"\n",
    "candidates = {\"\"\"SELECT 'T1'.'City', 'T1'.'Low Grade', 'T2'.'Latitude' FROM 'frpm' AS 'T1' INNER JOIN 'schools' AS 'T2' ON 'T1'.'CDSCode' = 'T2'.'CDSCode' WHERE 'T2'.'State' = 'CA' AND 'T2'.'Latitude' = (SELECT MIN('T2'.'Latitude') FROM 'schools' AS 'T2' WHERE 'T2'.'State' = 'CA')\"\"\": 'DAC',\n",
    "    \"\"\"SELECT T1.city, T1.school_name, T1.lowest_grade\n",
    "FROM (\n",
    "    SELECT S1.city, S1.school_name, S1.grade, MIN(C1.latitude) AS lowest_latitude\n",
    "    FROM schools AS S1\n",
    "    INNER JOIN coordinates AS C1 ON S1.id_school = C1.id_school\n",
    "    WHERE S1.state = 'CA'\n",
    "    GROUP BY S1.id_school\n",
    ") AS T1\n",
    "WHERE T1.lowest_latitude = (\n",
    "    SELECT MIN(lowest_latitude)\n",
    "    FROM (\n",
    "        SELECT S1.city, S1.school_name, S1.grade, MIN(C1.latitude) AS lowest_latitude\n",
    "        FROM schools AS S1\n",
    "        INNER JOIN coordinates AS C1 ON S1.id_school = C1.id_school\n",
    "        WHERE S1.state = 'CA'\n",
    "        GROUP BY S1.id_school\n",
    "    ) AS T2\n",
    ");\"\"\": 'DAC',\n",
    "    \"\"\"SELECT s.City, f.School Name, f.Low Grade\n",
    "    FROM schools s\n",
    "    JOIN frpm f ON s.CDSCode = f.CDSCode\n",
    "    WHERE s.State = 'CA'\n",
    "    AND s.Latitude = (SELECT MIN(Latitude) FROM schools WHERE State = 'CA')\n",
    "    LIMIT 1\"\"\": 'DAC'}\n",
    "\n",
    "\n",
    "model = 'tgi'\n",
    "markup_processor = AutoProcessor.from_pretrained(\"microsoft/markuplm-base\")\n",
    "markup_model = MarkupLMModel.from_pretrained(\"microsoft/markuplm-base\")\n",
    "\n",
    "ir = [\"`schools`.`City`.`San Diego`\", \"`frpm`.`Low Grade`\", \"`frpm`.`School Name`.`Vidya Mandir`\", \"`frpm`.`CDSCode`\", \"`schools`.`CDSCode`\", \"`schools`.`State`\", \"`schools`.`Latitude`\"]\n",
    "question = \"In which city can you find the school in the state of California with the lowest latitude coordinates and what is its lowest grade? Indicate the school name.\"\n",
    "hint = \"State of California refers to state = 'CA'\"\n",
    "ground_truth = \"SELECT T2.City, T1.`Low Grade`, T1.`School Name` FROM frpm AS T1 INNER JOIN schools AS T2 ON T1.CDSCode = T2.CDSCode WHERE T2.State = 'CA' ORDER BY T2.Latitude ASC LIMIT 1\"\n",
    "\n",
    "query_fix(\n",
    "    database_name=database_name,\n",
    "    database_path=database_path,\n",
    "    database_root_path=database_root_path,\n",
    "    candidates=candidates,\n",
    "    model=model,\n",
    "    ir=ir,\n",
    "    question=question,\n",
    "    ground_truth=ground_truth,\n",
    "    markup_model=markup_model,\n",
    "    markup_processor=markup_processor,\n",
    "    hint=hint\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sqlcopilot-cwclWRYE-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
